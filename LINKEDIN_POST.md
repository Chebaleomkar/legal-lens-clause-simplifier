âš–ï¸ My AI Model Failed 3 Times Before It Learned to Simplify Legal Jargon. Here's the Full Story.

I fine-tuned an LLM to translate legal contracts into plain English.

It broke 3 times before it worked. Here's the real journey ğŸ‘‡

â€” â€” â€”

ğ—™ğ—®ğ—¶ğ—¹ğ˜‚ğ—¿ğ—² #ğŸ­: ğ—§ğ—µğ—² ğ——ğ—®ğ˜ğ—® ğ—§ğ—¿ğ—®ğ—½

Started with the CUAD dataset (510+ real SEC-filed contracts). But CUAD only has complex clauses â€” no simplified versions.

So I built a script to generate parallel training data. Got 110 pairs. But 90% of the targets defaulted to the same generic placeholder. I didn't realize it yet.

ğ—™ğ—®ğ—¶ğ—¹ğ˜‚ğ—¿ğ—² #ğŸ®: ğ—¡ğ—®ğ—¡ ğ—Ÿğ—¼ğ˜€ğ˜€ğ—²ğ˜€ & ğ— ğ—¼ğ—±ğ—² ğ—–ğ—¼ğ—¹ğ—¹ğ—®ğ—½ğ˜€ğ—²

Picked FLAN-T5 + LoRA. Enabled fp16.

Training Loss: 0.000000 | Validation Loss: NaN

T5 is unstable in 16-bit precision. Fixed that. Retrained on Colab.

New output for EVERY input: "This clause applies only to the parties."

Mode collapse. The model memorized the one repeated placeholder from my dataset.

ğ—™ğ—®ğ—¶ğ—¹ğ˜‚ğ—¿ğ—² #ğŸ¯: ğ—•ğ—²ğ˜ğ˜ğ—²ğ—¿ ğ——ğ—®ğ˜ğ—®, ğ—¦ğ˜ğ—¶ğ—¹ğ—¹ ğ—•ğ—¿ğ—¼ğ—¸ğ—²ğ—»

Rebuilt the dataset â€” 2,000 unique pairs across 8+ legal categories.

FLAN-T5 output: "The failure a legal problem in a legal problem."

Gibberish. The Seq2Seq architecture + aggressive learning rate destroyed the model's language ability.

â€” â€” â€”

ğ—§ğ—µğ—² ğ—£ğ—¶ğ˜ƒğ—¼ğ˜ ğ—§ğ—µğ—®ğ˜ ğ—–ğ—µğ—®ğ—»ğ—´ğ—²ğ—± ğ—˜ğ˜ƒğ—²ğ—¿ğ˜†ğ˜ğ—µğ—¶ğ—»ğ—´

Switched to Google's Gemma-2B with a completely different strategy:

â†’ QLoRA (4-bit quantization) â€” 2.5B params on a free Colab T4
â†’ Only 921,600 trainable params (0.037% of total)
â†’ SFTTrainer from TRL with Gemma's chat template

Training loss: 3.58 â†’ 0.77 in 25 minutes.

Input: "In witness whereof, the parties hereto have executed this Agreement..."
Output: "The parties mentioned in this clause have done everything that is in the next clause."

It worked. Not a placeholder. Not gibberish. A real simplification.

â€” â€” â€”

ğ—ğ—²ğ˜† ğ—Ÿğ—²ğ˜€ğ˜€ğ—¼ğ—»ğ˜€:

1. Data quality > quantity. 2,000 curated pairs beat 10,000 generic ones.
2. Architecture matters. FLAN-T5 failed. Gemma-2B nailed it.
3. QLoRA democratizes fine-tuning. 2.5B params on a free GPU is real.
4. ML debugging is an engineering skill. NaN, mode collapse, gibberish â€” each taught me more than any course.

ğ—§ğ—²ğ—°ğ—µ ğ—¦ğ˜ğ—®ğ—°ğ—¸: Python Â· HuggingFace Â· PEFT/LoRA Â· TRL Â· bitsandbytes Â· Colab T4

Open-source on GitHub (link in comments).

â™»ï¸ Repost if you believe AI should make legal documents accessible to everyone.

#AI #MachineLearning #LLM #NLP #Gemma #HuggingFace #LegalTech #QLoRA #BuildInPublic #OpenSource
