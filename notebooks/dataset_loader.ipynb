{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bdb48d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\AI\\huggingface\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"theatticusproject/cuad\", verification_mode=\"no_checks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9c20bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['pdf'],\n",
      "        num_rows: 511\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae64aa1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pdf']\n"
     ]
    }
   ],
   "source": [
    "print(ds['train'].column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7ca2bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasheet for Contract Understanding Atticus Dataset (CUAD)\n",
      "I.MOTIVATION\n",
      "A. Who created the dataset (e.g., which team, research group) and on behalf of which entity (e.g. company,\n",
      "institution, organization)?\n",
      "The Atticus Project is a non-profit organization whose mission is to harness the power of AI to accelerate\n",
      "accurate and efficient contract review. The Atticus Project started as a grassroots movement by experienced\n",
      "lawyers in public companies and leading law firms aiming to achieve high-quality, low-cost, accurate and timely\n",
      "contract review using AI. It was officially incorporated as a California nonprofit public benefit corporation in\n",
      "January 2020.\n",
      "B. Did they fund it themselves? If there is an associated grant, please provide the name of the grantor and\n",
      "the grant name and number.\n",
      "The Atticus Project relies 100% on unpaid volunteers who are organized around the single mission of changing\n",
      "the legal industry by leveraging AI.\n",
      "C. For what purpose was the data set created? Was there a specific task in mind? If so, please specify the\n",
      "result type (e.g. unit) to be expected.\n",
      "The original specific task and the intended use case of the dataset is to facilitate the development of accurate AI\n",
      "algorithms for contract review in corporate transactions. Contract review refers to the process where human\n",
      "lawyers physically search through hundreds or thousands of contracts to find a few types of legal provisions. This\n",
      "process is time consuming, costly and prone to human error. The dataset aims to accelerate this process by\n",
      "leveraging AI. However, as development of this dataset progressed, there has not been any datasets identifying\n",
      "the different components of a legal contract. We hope that this dataset can be a catalyst to spur development of\n",
      "AI-models focused on legal contracts that can be an aid for legal practitioners. For example, one use could be an\n",
      "AI-model that can identify the expiration dates of contracts to remind a party when a contract needs to be\n",
      "renewed, a product that can generate a disclosure schedule for the seller as part of an acquisition or search for\n",
      "contracts that should be divested as part of a divestiture.\n",
      "However, the dataset should not be solely used for contract drafting, contract management, dispute resolution\n",
      "(incl. litigation) or provision of legal advice. In those situations, qualified human lawyers should still analyze and\n",
      "review any output. Instead, there are still a number of possibilities that AI can be developed as tools for legal\n",
      "practitioners and this dataset is intended to spur the development of such tools.\n",
      "II. COMPOSITION\n",
      "C. What do the instances (of each type, if appropriate) that comprise the data set represent? (e.g.\n",
      "documents, photos, people, countries).\n",
      "Each instance is a commercial contract sourced from the EDGAR (Electronic Data Gathering, Analysis, and\n",
      "Retrieval) system used by the U.S. Securities and Exchange Commission (SEC). Publicly traded companies in\n",
      "the United States and some foreign companies are required to file certain material contracts under SEC rules.\n",
      "Access to these contracts is available to the public for free at https://www.sec.gov/edgar.\n",
      "B. How many instances (of each type, if appropriate) are there in total?\n",
      "The latest release (CUAD v.1) has over 13,000 labels in 510 contracts. Future releases will include additional\n",
      "labels and contracts.\n"
     ]
    }
   ],
   "source": [
    "# Access the first document's PDF object\n",
    "first_pdf = ds['train'][0]['pdf']\n",
    "\n",
    "# Preview the text from the first page\n",
    "print(first_pdf.pages[0].extract_text())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc54e095",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 511/511 [00:00<00:00, 573.45 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to: e:\\AI\\huggingface\\legalLens\\data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Save the dataset object to a folder named 'dataset' in your current directory\n",
    "ds.save_to_disk(\"../data\")\n",
    "\n",
    "print(f\"Dataset saved to: {os.path.abspath('../data')}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
